{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning of ResNet50\r\n",
    "\r\n",
    "The purpose of this notebook is to reimplement the results of the following paper:\r\n",
    "\r\n",
    "* https://link.springer.com/article/10.1007%2Fs00521-020-05437-x \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "Data source: \r\n",
    "\r\n",
    "* https://www.kaggle.com/mloey1/covid19-chest-ct-image-augmentation-gan-dataset "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sys\r\n",
    "sys.path.append(\"../\")\r\n",
    "from covidct.dataset import *\r\n",
    "\r\n",
    "path = '../data/'\r\n",
    "\r\n",
    "train_data = CovidCTDataset(path, with_aug=False, with_cgan=False, split = 'train')\r\n",
    "val_data = CovidCTDataset(path, with_aug=False, with_cgan=False, split = 'val')\r\n",
    "test_data = CovidCTDataset(path, with_aug=False, with_cgan=False, split = 'test')\r\n",
    "\r\n",
    "print(len(train_data))\r\n",
    "print(len(val_data))\r\n",
    "print(len(test_data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "425\n",
      "118\n",
      "199\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading ResNet50 pretrained model\r\n",
    "\r\n",
    "https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\r\n",
    "\r\n",
    "num_ftrs = resnet.fc.in_features\r\n",
    "\r\n",
    "resnet.fc = torch.nn.Linear(2048, 2)\r\n",
    "\r\n",
    "resnet"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using cache found in C:\\Users\\Alex/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer learning with COVID-CT data to ResNet50 model\r\n",
    "\r\n",
    "## define model training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "from tqdm import tqdm\r\n",
    "import copy\r\n",
    "\r\n",
    "def train_resnet(model, data, criterion, optimizer, n_epochs):\r\n",
    "    '''f'''\r\n",
    "\r\n",
    "    val_acc_history = []\r\n",
    "    best_acc = 0.0\r\n",
    "\r\n",
    "    # iterating epochs\r\n",
    "    for epoch in tqdm(range(n_epochs)):\r\n",
    "        for phase in ['train', 'val']:\r\n",
    "            if phase == 'train':\r\n",
    "                resnet.train()\r\n",
    "            else:\r\n",
    "                resnet.eval()\r\n",
    "\r\n",
    "            running_loss = 0.0\r\n",
    "            running_corrects = 0\r\n",
    "\r\n",
    "            # iterating data\r\n",
    "            for x, y in data[phase]:\r\n",
    "                inputs = x.to(device)\r\n",
    "                labels = y.to(device)\r\n",
    "\r\n",
    "                optimizer.zero_grad()\r\n",
    "\r\n",
    "                # forward\r\n",
    "                with torch.set_grad_enabled(phase == 'train'):\r\n",
    "                    outputs = model(inputs)\r\n",
    "                    loss = criterion(outputs, labels)\r\n",
    "\r\n",
    "                    _, predictions = torch.max(outputs, 1)\r\n",
    "\r\n",
    "                    if phase == 'train':\r\n",
    "                        loss.backward()\r\n",
    "                        optimizer.step()\r\n",
    "\r\n",
    "                # update running values\r\n",
    "                running_loss += loss.item() * inputs.size(0)\r\n",
    "                running_corrects += torch.sum(predictions == labels.data)\r\n",
    "\r\n",
    "            epoch_loss = running_loss / len(data[phase].dataset)\r\n",
    "            epoch_acc = running_corrects.double() / len(data[phase].dataset)\r\n",
    "\r\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\r\n",
    "\r\n",
    "            # deep copy the model\r\n",
    "            if phase == 'val' and epoch_acc > best_acc:\r\n",
    "                best_acc = epoch_acc\r\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\r\n",
    "\r\n",
    "            if phase == 'val':\r\n",
    "                val_acc_history.append(epoch_acc)\r\n",
    "        print()\r\n",
    "\r\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\r\n",
    "\r\n",
    "    # load best model weights\r\n",
    "    model.load_state_dict(best_model_wts)\r\n",
    "    return model, val_acc_history\r\n",
    "\r\n",
    "\r\n",
    "def set_parameter_requires_grad(model, feature_extracting):\r\n",
    "    if feature_extracting:\r\n",
    "        for param in model.parameters():\r\n",
    "            param.requires_gradd = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## creating optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# model to device\r\n",
    "resnet = resnet.to(device)\r\n",
    "\r\n",
    "feature_extract = True\r\n",
    "\r\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\r\n",
    "#  finetuning we will be updating all parameters. However, if we are\r\n",
    "#  doing feature extract method, we will only update the parameters\r\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\r\n",
    "#  is True.\r\n",
    "\r\n",
    "params_to_update = resnet.parameters()\r\n",
    "print('Parameters to learn:')\r\n",
    "\r\n",
    "if feature_extract:\r\n",
    "    params_to_update = []\r\n",
    "    for name, param in resnet.named_parameters():\r\n",
    "        if param.requires_grad == True:\r\n",
    "            params_to_update.append(param)\r\n",
    "            print('\\t', name)\r\n",
    "else:\r\n",
    "    for name, param in resnet.named_parameters():\r\n",
    "        if param.requires_grad == True:\r\n",
    "            print('\\t', name)\r\n",
    "\r\n",
    "optimizer_ft = torch.optim.Adam(params_to_update, lr = 0.001)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameters to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.0.conv3.weight\n",
      "\t layer1.0.bn3.weight\n",
      "\t layer1.0.bn3.bias\n",
      "\t layer1.0.downsample.0.weight\n",
      "\t layer1.0.downsample.1.weight\n",
      "\t layer1.0.downsample.1.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer1.1.conv3.weight\n",
      "\t layer1.1.bn3.weight\n",
      "\t layer1.1.bn3.bias\n",
      "\t layer1.2.conv1.weight\n",
      "\t layer1.2.bn1.weight\n",
      "\t layer1.2.bn1.bias\n",
      "\t layer1.2.conv2.weight\n",
      "\t layer1.2.bn2.weight\n",
      "\t layer1.2.bn2.bias\n",
      "\t layer1.2.conv3.weight\n",
      "\t layer1.2.bn3.weight\n",
      "\t layer1.2.bn3.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.conv3.weight\n",
      "\t layer2.0.bn3.weight\n",
      "\t layer2.0.bn3.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer2.1.conv3.weight\n",
      "\t layer2.1.bn3.weight\n",
      "\t layer2.1.bn3.bias\n",
      "\t layer2.2.conv1.weight\n",
      "\t layer2.2.bn1.weight\n",
      "\t layer2.2.bn1.bias\n",
      "\t layer2.2.conv2.weight\n",
      "\t layer2.2.bn2.weight\n",
      "\t layer2.2.bn2.bias\n",
      "\t layer2.2.conv3.weight\n",
      "\t layer2.2.bn3.weight\n",
      "\t layer2.2.bn3.bias\n",
      "\t layer2.3.conv1.weight\n",
      "\t layer2.3.bn1.weight\n",
      "\t layer2.3.bn1.bias\n",
      "\t layer2.3.conv2.weight\n",
      "\t layer2.3.bn2.weight\n",
      "\t layer2.3.bn2.bias\n",
      "\t layer2.3.conv3.weight\n",
      "\t layer2.3.bn3.weight\n",
      "\t layer2.3.bn3.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.conv3.weight\n",
      "\t layer3.0.bn3.weight\n",
      "\t layer3.0.bn3.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer3.1.conv3.weight\n",
      "\t layer3.1.bn3.weight\n",
      "\t layer3.1.bn3.bias\n",
      "\t layer3.2.conv1.weight\n",
      "\t layer3.2.bn1.weight\n",
      "\t layer3.2.bn1.bias\n",
      "\t layer3.2.conv2.weight\n",
      "\t layer3.2.bn2.weight\n",
      "\t layer3.2.bn2.bias\n",
      "\t layer3.2.conv3.weight\n",
      "\t layer3.2.bn3.weight\n",
      "\t layer3.2.bn3.bias\n",
      "\t layer3.3.conv1.weight\n",
      "\t layer3.3.bn1.weight\n",
      "\t layer3.3.bn1.bias\n",
      "\t layer3.3.conv2.weight\n",
      "\t layer3.3.bn2.weight\n",
      "\t layer3.3.bn2.bias\n",
      "\t layer3.3.conv3.weight\n",
      "\t layer3.3.bn3.weight\n",
      "\t layer3.3.bn3.bias\n",
      "\t layer3.4.conv1.weight\n",
      "\t layer3.4.bn1.weight\n",
      "\t layer3.4.bn1.bias\n",
      "\t layer3.4.conv2.weight\n",
      "\t layer3.4.bn2.weight\n",
      "\t layer3.4.bn2.bias\n",
      "\t layer3.4.conv3.weight\n",
      "\t layer3.4.bn3.weight\n",
      "\t layer3.4.bn3.bias\n",
      "\t layer3.5.conv1.weight\n",
      "\t layer3.5.bn1.weight\n",
      "\t layer3.5.bn1.bias\n",
      "\t layer3.5.conv2.weight\n",
      "\t layer3.5.bn2.weight\n",
      "\t layer3.5.bn2.bias\n",
      "\t layer3.5.conv3.weight\n",
      "\t layer3.5.bn3.weight\n",
      "\t layer3.5.bn3.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.conv3.weight\n",
      "\t layer4.0.bn3.weight\n",
      "\t layer4.0.bn3.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t layer4.1.conv3.weight\n",
      "\t layer4.1.bn3.weight\n",
      "\t layer4.1.bn3.bias\n",
      "\t layer4.2.conv1.weight\n",
      "\t layer4.2.bn1.weight\n",
      "\t layer4.2.bn1.bias\n",
      "\t layer4.2.conv2.weight\n",
      "\t layer4.2.bn2.weight\n",
      "\t layer4.2.bn2.bias\n",
      "\t layer4.2.conv3.weight\n",
      "\t layer4.2.bn3.weight\n",
      "\t layer4.2.bn3.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# hyperparameters\r\n",
    "n_epochs = 50\r\n",
    "batch_size = 32\r\n",
    "\r\n",
    "data = {'train': torch.utils.data.DataLoader(train_data, shuffle = True, batch_size = batch_size)\r\n",
    "        ,'val': torch.utils.data.DataLoader(val_data, shuffle = True, batch_size = batch_size)\r\n",
    "        ,'test': torch.utils.data.DataLoader(test_data, shuffle = True, batch_size = batch_size)}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "resnet, hist = train_resnet(resnet, data, criterion, optimizer_ft, n_epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train Loss: 0.6852 Acc: 0.7012\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  2%|▏         | 1/50 [03:15<2:39:18, 195.07s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 27.2574 Acc: 0.6186\n",
      "\n",
      "train Loss: 0.5757 Acc: 0.7341\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  4%|▍         | 2/50 [06:32<2:37:15, 196.57s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 12.6519 Acc: 0.4661\n",
      "\n",
      "train Loss: 0.4505 Acc: 0.7929\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  6%|▌         | 3/50 [09:51<2:34:38, 197.41s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 2.3632 Acc: 0.6017\n",
      "\n",
      "train Loss: 0.4130 Acc: 0.8000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  8%|▊         | 4/50 [13:09<2:31:41, 197.86s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.6840 Acc: 0.4661\n",
      "\n",
      "train Loss: 0.3331 Acc: 0.8682\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 10%|█         | 5/50 [16:21<2:26:48, 195.75s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 2.0972 Acc: 0.6441\n",
      "\n",
      "train Loss: 0.3394 Acc: 0.8541\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 12%|█▏        | 6/50 [19:29<2:21:33, 193.03s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 2.5832 Acc: 0.6102\n",
      "\n",
      "train Loss: 0.3178 Acc: 0.8612\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 14%|█▍        | 7/50 [22:58<2:22:11, 198.41s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.1041 Acc: 0.5932\n",
      "\n",
      "train Loss: 0.2431 Acc: 0.9176\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 16%|█▌        | 8/50 [26:21<2:19:51, 199.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.2090 Acc: 0.6186\n",
      "\n",
      "train Loss: 0.2130 Acc: 0.9388\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 18%|█▊        | 9/50 [29:42<2:16:50, 200.26s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.3465 Acc: 0.6780\n",
      "\n",
      "train Loss: 0.1046 Acc: 0.9765\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 10/50 [33:53<2:23:45, 215.64s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 2.1087 Acc: 0.5254\n",
      "\n",
      "train Loss: 0.1860 Acc: 0.9224\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 22%|██▏       | 11/50 [38:25<2:31:30, 233.08s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.1300 Acc: 0.6695\n",
      "\n",
      "train Loss: 0.2203 Acc: 0.9153\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 24%|██▍       | 12/50 [42:49<2:33:37, 242.56s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.4058 Acc: 0.5424\n",
      "\n",
      "train Loss: 0.1076 Acc: 0.9553\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 26%|██▌       | 13/50 [47:06<2:32:09, 246.73s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 0.8408 Acc: 0.7119\n",
      "\n",
      "train Loss: 0.0461 Acc: 0.9882\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 28%|██▊       | 14/50 [50:49<2:23:46, 239.62s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 3.2942 Acc: 0.5593\n",
      "\n",
      "train Loss: 0.0308 Acc: 0.9929\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 30%|███       | 15/50 [55:24<2:26:01, 250.33s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.4154 Acc: 0.6949\n",
      "\n",
      "train Loss: 0.0964 Acc: 0.9671\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 32%|███▏      | 16/50 [1:00:39<2:32:55, 269.86s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.8803 Acc: 0.7034\n",
      "\n",
      "train Loss: 0.1051 Acc: 0.9647\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 34%|███▍      | 17/50 [1:05:33<2:32:24, 277.12s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 2.4093 Acc: 0.6271\n",
      "\n",
      "train Loss: 0.0720 Acc: 0.9718\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 36%|███▌      | 18/50 [1:10:19<2:29:15, 279.85s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.1889 Acc: 0.7119\n",
      "\n",
      "train Loss: 0.0483 Acc: 0.9882\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 38%|███▊      | 19/50 [1:15:26<2:28:44, 287.87s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 2.9179 Acc: 0.6356\n",
      "\n",
      "train Loss: 0.1828 Acc: 0.9412\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|████      | 20/50 [1:20:14<2:23:55, 287.85s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 5.0796 Acc: 0.4661\n",
      "\n",
      "train Loss: 0.1999 Acc: 0.9365\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 42%|████▏     | 21/50 [1:24:55<2:18:07, 285.77s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.4606 Acc: 0.7119\n",
      "\n",
      "train Loss: 0.1107 Acc: 0.9600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 44%|████▍     | 22/50 [1:29:25<2:11:13, 281.18s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 4.0123 Acc: 0.5085\n",
      "\n",
      "train Loss: 0.0511 Acc: 0.9835\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 46%|████▌     | 23/50 [1:33:45<2:03:40, 274.84s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 0.5406 Acc: 0.7627\n",
      "\n",
      "train Loss: 0.0305 Acc: 0.9906\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 48%|████▊     | 24/50 [1:38:24<1:59:39, 276.12s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.1049 Acc: 0.7034\n",
      "\n",
      "train Loss: 0.0178 Acc: 0.9953\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|█████     | 25/50 [1:42:58<1:54:46, 275.47s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.2885 Acc: 0.7542\n",
      "\n",
      "train Loss: 0.0174 Acc: 0.9953\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 52%|█████▏    | 26/50 [1:47:45<1:51:32, 278.86s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 0.9243 Acc: 0.7797\n",
      "\n",
      "train Loss: 0.0142 Acc: 0.9953\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 54%|█████▍    | 27/50 [1:52:18<1:46:10, 276.97s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.4615 Acc: 0.7542\n",
      "\n",
      "train Loss: 0.0080 Acc: 0.9976\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 56%|█████▌    | 28/50 [1:57:16<1:43:56, 283.47s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.3260 Acc: 0.7288\n",
      "\n",
      "train Loss: 0.0252 Acc: 0.9929\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 58%|█████▊    | 29/50 [2:02:32<1:42:35, 293.14s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.0864 Acc: 0.7458\n",
      "\n",
      "train Loss: 0.0145 Acc: 0.9953\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 60%|██████    | 30/50 [2:07:19<1:37:05, 291.29s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 2.4515 Acc: 0.6949\n",
      "\n",
      "train Loss: 0.0243 Acc: 0.9859\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 62%|██████▏   | 31/50 [2:12:03<1:31:30, 288.96s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 3.5543 Acc: 0.6017\n",
      "\n",
      "train Loss: 0.1440 Acc: 0.9529\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 64%|██████▍   | 32/50 [2:16:34<1:25:06, 283.72s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 2.5268 Acc: 0.6610\n",
      "\n",
      "train Loss: 0.2529 Acc: 0.9200\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 66%|██████▌   | 33/50 [2:21:11<1:19:47, 281.61s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.6882 Acc: 0.6864\n",
      "\n",
      "train Loss: 0.1176 Acc: 0.9718\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 68%|██████▊   | 34/50 [2:25:33<1:13:32, 275.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.0465 Acc: 0.6780\n",
      "\n",
      "train Loss: 0.1958 Acc: 0.9412\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 70%|███████   | 35/50 [2:30:08<1:08:52, 275.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.4789 Acc: 0.6271\n",
      "\n",
      "train Loss: 0.1412 Acc: 0.9365\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 72%|███████▏  | 36/50 [2:34:13<1:02:11, 266.54s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 0.8499 Acc: 0.6441\n",
      "\n",
      "train Loss: 0.0810 Acc: 0.9694\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 74%|███████▍  | 37/50 [2:38:40<57:45, 266.60s/it]  "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 2.2004 Acc: 0.6271\n",
      "\n",
      "train Loss: 0.0248 Acc: 0.9953\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 76%|███████▌  | 38/50 [2:42:44<51:58, 259.91s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.5279 Acc: 0.7203\n",
      "\n",
      "train Loss: 0.0106 Acc: 0.9976\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 78%|███████▊  | 39/50 [2:46:57<47:15, 257.78s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.2390 Acc: 0.6949\n",
      "\n",
      "train Loss: 0.0107 Acc: 0.9976\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 80%|████████  | 40/50 [2:50:54<41:54, 251.42s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.2000 Acc: 0.7627\n",
      "\n",
      "train Loss: 0.0081 Acc: 0.9976\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 82%|████████▏ | 41/50 [2:54:14<35:23, 235.91s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.3925 Acc: 0.7458\n",
      "\n",
      "train Loss: 0.0056 Acc: 0.9976\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 84%|████████▍ | 42/50 [2:57:20<29:28, 221.05s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.2750 Acc: 0.7373\n",
      "\n",
      "train Loss: 0.0016 Acc: 1.0000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 86%|████████▌ | 43/50 [3:00:27<24:35, 210.73s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.4624 Acc: 0.6864\n",
      "\n",
      "train Loss: 0.0024 Acc: 1.0000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 88%|████████▊ | 44/50 [3:03:32<20:19, 203.25s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.2732 Acc: 0.7373\n",
      "\n",
      "train Loss: 0.0127 Acc: 0.9953\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 90%|█████████ | 45/50 [3:06:35<16:25, 197.05s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 4.6056 Acc: 0.6102\n",
      "\n",
      "train Loss: 0.1665 Acc: 0.9388\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 92%|█████████▏| 46/50 [3:09:38<12:51, 192.97s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 12.5771 Acc: 0.5085\n",
      "\n",
      "train Loss: 0.2976 Acc: 0.9200\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 94%|█████████▍| 47/50 [3:12:45<09:32, 190.93s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.7582 Acc: 0.5508\n",
      "\n",
      "train Loss: 0.1528 Acc: 0.9482\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 96%|█████████▌| 48/50 [3:15:48<06:17, 188.64s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 1.1489 Acc: 0.6864\n",
      "\n",
      "train Loss: 0.0677 Acc: 0.9788\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 98%|█████████▊| 49/50 [3:18:54<03:07, 187.91s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 0.7642 Acc: 0.6864\n",
      "\n",
      "train Loss: 0.0250 Acc: 0.9953\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50/50 [3:22:11<00:00, 242.62s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val Loss: 0.9440 Acc: 0.7458\n",
      "\n",
      "Best val Acc: 0.779661\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing model on test dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "with torch.no_grad():\r\n",
    "    resnet.eval()\r\n",
    "    y_pred = []\r\n",
    "    y_true = []\r\n",
    "    \r\n",
    "    for img, lab in data['test']:\r\n",
    "        batch_pred = resnet(img)\r\n",
    "        for i, (y0, y1) in enumerate(batch_pred):\r\n",
    "            if y0 > y1:\r\n",
    "                pred = 0\r\n",
    "            else:\r\n",
    "                pred = 1\r\n",
    "            y_pred.append(pred)\r\n",
    "            y_true.append(lab[i].item())\r\n",
    "\r\n",
    "print(y_pred)\r\n",
    "print(y_true)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "import sklearn.metrics as metrics\r\n",
    "\r\n",
    "print('true class')\r\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\r\n",
    "print('--------')\r\n",
    "print(f'accuracy: {metrics.accuracy_score(y_true, y_pred)}')\r\n",
    "print(f'precision: {metrics.precision_score(y_true, y_pred)}')\r\n",
    "print(f'recall: {metrics.recall_score(y_true, y_pred)}')\r\n",
    "print(f'f1 score: {metrics.f1_score(y_true, y_pred)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "true class\n",
      "[[83 22]\n",
      " [40 54]]\n",
      "--------\n",
      "accuracy: 0.6884422110552764\n",
      "precision: 0.7105263157894737\n",
      "recall: 0.574468085106383\n",
      "f1 score: 0.6352941176470589\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving model to repo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "torch.save(resnet.state_dict(), '../models/ResNet50_raw/model.wts')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}